{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "label_dict = {\n",
    "    \"Aerodactyl\": 0,\n",
    "    \"Bulbasaur\": 1,\n",
    "    \"Charmander\": 2,\n",
    "    \"Dratini\": 3,\n",
    "    \"Fearow\": 4,\n",
    "    \"Meowth\": 5,\n",
    "    \"Pikachu\": 6,\n",
    "    \"Psyduck\": 7,\n",
    "    \"Spearow\": 8,\n",
    "    \"Squirtle\": 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aerodactyl', 'Bulbasaur', 'Charmander', 'Dratini', 'Fearow', 'Meowth', 'Pikachu', 'Psyduck', 'Spearow', 'Squirtle']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folders = os.listdir(\"Train\")\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\PIL\\Image.py:952: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "for ix in folders:\n",
    "  path = os.path.join(\"Train\", ix)\n",
    "  for im in os.listdir(path):\n",
    "    img = image.load_img(os.path.join(path,im), target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    image_data.append(img_array)\n",
    "    labels.append(label_dict[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "combined = list(zip(image_data, labels))\n",
    "random.shuffle(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data[:], labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1645, 224, 224, 3) (1645,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(image_data)\n",
    "Y_train = np.array(labels)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.reshape((-1,224,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4935, 224, 224, 1) (1645, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 64)      18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 220, 220, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 106, 106, 32)      51232     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 102, 102, 8)       6408      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 83232)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                832330    \n",
      "=================================================================\n",
      "Total params: 909,362\n",
      "Trainable params: 909,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3), activation='relu',input_shape=(224,224,3)))\n",
    "model.add(Convolution2D(64,(3,3), activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Convolution2D(32,(5,5), activation='relu'))\n",
    "model.add(Convolution2D(8,(5,5), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggmodel = VGG16(weights='imagenet', include_top= False, input_shape=(224,224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vggmodel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "av1 = GlobalAveragePooling2D()(vggmodel.output)\n",
    "fc1 = Dense(256, activation='relu')(av1)\n",
    "d1 = Dropout(0.5)(fc1)\n",
    "fc2 = Dense(10, activation='softmax')(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 14,848,586\n",
      "Trainable params: 133,898\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new = Model(inputs = vggmodel.input , outputs=fc2)\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00003)\n",
    "model_new.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = vggmodel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_extractor.reshape(feature_extractor.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_RF = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmodel.fit(X_for_RF, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990273556231003"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmodel.score(X_for_RF, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-1092a713df93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestfeature_extractor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvggmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtestfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "testfeature_extractor = vggmodel.predict(X_test)\n",
    "testfeatures = testfeature_extractor.reshape(testfeature_extractor.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testfeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ebbea3bf7397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'testfeatures' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = rfmodel.predict(testfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 7, 7, 7, 6, 6, 5, 6, 7,\n",
       "       4, 7, 1, 7, 2, 7, 7, 1, 2, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 9, 1, 9, 9, 1, 2, 6, 9, 1, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 2, 1, 9, 7, 9, 2, 1, 9, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 9, 6, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 2, 9, 2, 2, 2, 4, 2, 9, 2, 2, 1, 2, 2, 1, 2, 3,\n",
       "       0, 1, 3, 3, 2, 2, 3, 3, 3, 2, 1, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       0, 4, 4, 4, 1, 9, 2, 6, 9, 6, 1])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [50,10] and labels shape [500]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-37-ecfb5202df1e>:7) ]] [Op:__inference_train_function_1814]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ecfb5202df1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                  \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                  validation_split = 0.20)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\linta.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [50,10] and labels shape [500]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-37-ecfb5202df1e>:7) ]] [Op:__inference_train_function_1814]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "hist = model_new.fit(X_train, \n",
    "                 Y_train,\n",
    "                 shuffle = True,\n",
    "                 batch_size=50,\n",
    "                 epochs =2,\n",
    "                 steps_per_epoch=30,\n",
    "                 validation_split = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0.jpg', 'test_1.jpg', 'test_10.jpg', 'test_100.jpg', 'test_101.jpg', 'test_102.jpg', 'test_103.jpg', 'test_104.jpg', 'test_105.jpg', 'test_106.jpg', 'test_107.jpg', 'test_108.jpg', 'test_109.jpg', 'test_11.jpg', 'test_110.jpg', 'test_111.jpg', 'test_112.jpg', 'test_113.jpg', 'test_114.jpg', 'test_115.jpg', 'test_116.jpg', 'test_117.jpg', 'test_118.jpg', 'test_119.jpg', 'test_12.jpg', 'test_120.jpg', 'test_121.jpg', 'test_122.jpg', 'test_123.jpg', 'test_124.jpg', 'test_125.jpg', 'test_126.jpg', 'test_127.jpg', 'test_128.jpg', 'test_129.jpg', 'test_13.jpg', 'test_130.jpg', 'test_131.jpg', 'test_132.jpg', 'test_133.jpg', 'test_134.jpg', 'test_135.jpg', 'test_136.jpg', 'test_137.jpg', 'test_138.jpg', 'test_139.jpg', 'test_14.jpg', 'test_140.jpg', 'test_141.jpg', 'test_142.jpg', 'test_143.jpg', 'test_144.jpg', 'test_145.jpg', 'test_146.jpg', 'test_147.jpg', 'test_148.jpg', 'test_149.jpg', 'test_15.jpg', 'test_150.jpg', 'test_151.jpg', 'test_152.jpg', 'test_153.jpg', 'test_154.jpg', 'test_155.jpg', 'test_156.jpg', 'test_157.jpg', 'test_158.jpg', 'test_159.jpg', 'test_16.jpg', 'test_160.jpg', 'test_161.jpg', 'test_162.jpg', 'test_163.jpg', 'test_164.jpg', 'test_165.jpg', 'test_166.jpg', 'test_167.jpg', 'test_168.jpg', 'test_169.jpg', 'test_17.jpg', 'test_170.jpg', 'test_171.jpg', 'test_172.jpg', 'test_173.jpg', 'test_174.jpg', 'test_175.jpg', 'test_176.jpg', 'test_177.jpg', 'test_178.jpg', 'test_179.jpg', 'test_18.jpg', 'test_180.jpg', 'test_181.jpg', 'test_182.jpg', 'test_183.jpg', 'test_184.jpg', 'test_185.jpg', 'test_186.jpg', 'test_19.jpg', 'test_2.jpg', 'test_20.jpg', 'test_21.jpg', 'test_22.jpg', 'test_23.jpg', 'test_24.jpg', 'test_25.jpg', 'test_26.jpg', 'test_27.jpg', 'test_28.jpg', 'test_29.jpg', 'test_3.jpg', 'test_30.jpg', 'test_31.jpg', 'test_32.jpg', 'test_33.jpg', 'test_34.jpg', 'test_35.jpg', 'test_36.jpg', 'test_37.jpg', 'test_38.jpg', 'test_39.jpg', 'test_4.jpg', 'test_40.jpg', 'test_41.jpg', 'test_42.jpg', 'test_43.jpg', 'test_44.jpg', 'test_45.jpg', 'test_46.jpg', 'test_47.jpg', 'test_48.jpg', 'test_49.jpg', 'test_5.jpg', 'test_50.jpg', 'test_51.jpg', 'test_52.jpg', 'test_53.jpg', 'test_54.jpg', 'test_55.jpg', 'test_56.jpg', 'test_57.jpg', 'test_58.jpg', 'test_59.jpg', 'test_6.jpg', 'test_60.jpg', 'test_61.jpg', 'test_62.jpg', 'test_63.jpg', 'test_64.jpg', 'test_65.jpg', 'test_66.jpg', 'test_67.jpg', 'test_68.jpg', 'test_69.jpg', 'test_7.jpg', 'test_70.jpg', 'test_71.jpg', 'test_72.jpg', 'test_73.jpg', 'test_74.jpg', 'test_75.jpg', 'test_76.jpg', 'test_77.jpg', 'test_78.jpg', 'test_79.jpg', 'test_8.jpg', 'test_80.jpg', 'test_81.jpg', 'test_82.jpg', 'test_83.jpg', 'test_84.jpg', 'test_85.jpg', 'test_86.jpg', 'test_87.jpg', 'test_88.jpg', 'test_89.jpg', 'test_9.jpg', 'test_90.jpg', 'test_91.jpg', 'test_92.jpg', 'test_93.jpg', 'test_94.jpg', 'test_95.jpg', 'test_96.jpg', 'test_97.jpg', 'test_98.jpg', 'test_99.jpg']\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(\"Test/images\")\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "py = Path(\"Test/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_0.jpg\n",
      "test_1.jpg\n",
      "test_10.jpg\n",
      "test_100.jpg\n",
      "test_101.jpg\n",
      "test_102.jpg\n",
      "test_103.jpg\n",
      "test_104.jpg\n",
      "test_105.jpg\n",
      "test_106.jpg\n",
      "test_107.jpg\n",
      "test_108.jpg\n",
      "test_109.jpg\n",
      "test_11.jpg\n",
      "test_110.jpg\n",
      "test_111.jpg\n",
      "test_112.jpg\n",
      "test_113.jpg\n",
      "test_114.jpg\n",
      "test_115.jpg\n",
      "test_116.jpg\n",
      "test_117.jpg\n",
      "test_118.jpg\n",
      "test_119.jpg\n",
      "test_12.jpg\n",
      "test_120.jpg\n",
      "test_121.jpg\n",
      "test_122.jpg\n",
      "test_123.jpg\n",
      "test_124.jpg\n",
      "test_125.jpg\n",
      "test_126.jpg\n",
      "test_127.jpg\n",
      "test_128.jpg\n",
      "test_129.jpg\n",
      "test_13.jpg\n",
      "test_130.jpg\n",
      "test_131.jpg\n",
      "test_132.jpg\n",
      "test_133.jpg\n",
      "test_134.jpg\n",
      "test_135.jpg\n",
      "test_136.jpg\n",
      "test_137.jpg\n",
      "test_138.jpg\n",
      "test_139.jpg\n",
      "test_14.jpg\n",
      "test_140.jpg\n",
      "test_141.jpg\n",
      "test_142.jpg\n",
      "test_143.jpg\n",
      "test_144.jpg\n",
      "test_145.jpg\n",
      "test_146.jpg\n",
      "test_147.jpg\n",
      "test_148.jpg\n",
      "test_149.jpg\n",
      "test_15.jpg\n",
      "test_150.jpg\n",
      "test_151.jpg\n",
      "test_152.jpg\n",
      "test_153.jpg\n",
      "test_154.jpg\n",
      "test_155.jpg\n",
      "test_156.jpg\n",
      "test_157.jpg\n",
      "test_158.jpg\n",
      "test_159.jpg\n",
      "test_16.jpg\n",
      "test_160.jpg\n",
      "test_161.jpg\n",
      "test_162.jpg\n",
      "test_163.jpg\n",
      "test_164.jpg\n",
      "test_165.jpg\n",
      "test_166.jpg\n",
      "test_167.jpg\n",
      "test_168.jpg\n",
      "test_169.jpg\n",
      "test_17.jpg\n",
      "test_170.jpg\n",
      "test_171.jpg\n",
      "test_172.jpg\n",
      "test_173.jpg\n",
      "test_174.jpg\n",
      "test_175.jpg\n",
      "test_176.jpg\n",
      "test_177.jpg\n",
      "test_178.jpg\n",
      "test_179.jpg\n",
      "test_18.jpg\n",
      "test_180.jpg\n",
      "test_181.jpg\n",
      "test_182.jpg\n",
      "test_183.jpg\n",
      "test_184.jpg\n",
      "test_185.jpg\n",
      "test_186.jpg\n",
      "test_19.jpg\n",
      "test_2.jpg\n",
      "test_20.jpg\n",
      "test_21.jpg\n",
      "test_22.jpg\n",
      "test_23.jpg\n",
      "test_24.jpg\n",
      "test_25.jpg\n",
      "test_26.jpg\n",
      "test_27.jpg\n",
      "test_28.jpg\n",
      "test_29.jpg\n",
      "test_3.jpg\n",
      "test_30.jpg\n",
      "test_31.jpg\n",
      "test_32.jpg\n",
      "test_33.jpg\n",
      "test_34.jpg\n",
      "test_35.jpg\n",
      "test_36.jpg\n",
      "test_37.jpg\n",
      "test_38.jpg\n",
      "test_39.jpg\n",
      "test_4.jpg\n",
      "test_40.jpg\n",
      "test_41.jpg\n",
      "test_42.jpg\n",
      "test_43.jpg\n",
      "test_44.jpg\n",
      "test_45.jpg\n",
      "test_46.jpg\n",
      "test_47.jpg\n",
      "test_48.jpg\n",
      "test_49.jpg\n",
      "test_5.jpg\n",
      "test_50.jpg\n",
      "test_51.jpg\n",
      "test_52.jpg\n",
      "test_53.jpg\n",
      "test_54.jpg\n",
      "test_55.jpg\n",
      "test_56.jpg\n",
      "test_57.jpg\n",
      "test_58.jpg\n",
      "test_59.jpg\n",
      "test_6.jpg\n",
      "test_60.jpg\n",
      "test_61.jpg\n",
      "test_62.jpg\n",
      "test_63.jpg\n",
      "test_64.jpg\n",
      "test_65.jpg\n",
      "test_66.jpg\n",
      "test_67.jpg\n",
      "test_68.jpg\n",
      "test_69.jpg\n",
      "test_7.jpg\n",
      "test_70.jpg\n",
      "test_71.jpg\n",
      "test_72.jpg\n",
      "test_73.jpg\n",
      "test_74.jpg\n",
      "test_75.jpg\n",
      "test_76.jpg\n",
      "test_77.jpg\n",
      "test_78.jpg\n",
      "test_79.jpg\n",
      "test_8.jpg\n",
      "test_80.jpg\n",
      "test_81.jpg\n",
      "test_82.jpg\n",
      "test_83.jpg\n",
      "test_84.jpg\n",
      "test_85.jpg\n",
      "test_86.jpg\n",
      "test_87.jpg\n",
      "test_88.jpg\n",
      "test_89.jpg\n",
      "test_9.jpg\n",
      "test_90.jpg\n",
      "test_91.jpg\n",
      "test_92.jpg\n",
      "test_93.jpg\n",
      "test_94.jpg\n",
      "test_95.jpg\n",
      "test_96.jpg\n",
      "test_97.jpg\n",
      "test_98.jpg\n",
      "test_99.jpg\n"
     ]
    }
   ],
   "source": [
    "image_datay = []\n",
    "imagenames = []\n",
    "for img_path in py.glob(\"*.jpg\"):\n",
    "    label = str(img_path).split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    imagenames.append(label)\n",
    "    img = image.load_img(img_path,target_size=(224,224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    image_datay.append(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(image_datay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03799696e-03, 1.62578702e-01, 2.29534358e-01, 1.56259835e-02,\n",
       "        1.84799777e-03, 1.91970867e-05, 5.31319916e-01, 5.42507619e-02,\n",
       "        2.75206985e-04, 3.50992172e-03],\n",
       "       [1.96422679e-05, 1.42249063e-01, 8.45597148e-01, 2.07891819e-04,\n",
       "        3.12149408e-04, 5.80379947e-07, 1.07316766e-02, 1.20215904e-04,\n",
       "        6.39743894e-06, 7.55205983e-04],\n",
       "       [2.19978785e-04, 1.33305986e-03, 1.16040027e-02, 1.04188462e-06,\n",
       "        2.60446313e-07, 1.50661106e-06, 9.86825287e-01, 1.28195625e-05,\n",
       "        7.46054862e-09, 1.97184318e-06],\n",
       "       [5.18192954e-12, 2.20265074e-11, 1.70345942e-08, 3.08033894e-12,\n",
       "        2.06306196e-12, 8.67719592e-14, 1.00000000e+00, 6.59378761e-14,\n",
       "        6.00698190e-16, 1.75884741e-12],\n",
       "       [3.45372155e-06, 9.17249262e-01, 8.99219885e-03, 1.99538863e-06,\n",
       "        2.34635223e-07, 3.59822527e-09, 2.25580006e-05, 7.37144649e-02,\n",
       "        3.97633482e-10, 1.59046431e-05],\n",
       "       [1.01702993e-10, 5.23449620e-03, 9.89072084e-01, 3.66849775e-07,\n",
       "        1.89789385e-03, 2.96373006e-08, 3.77515238e-03, 3.10067483e-09,\n",
       "        1.90413029e-05, 1.04883793e-06],\n",
       "       [1.02047428e-08, 2.24636296e-05, 3.63451280e-02, 1.33561916e-05,\n",
       "        1.08059823e-04, 1.92345553e-08, 9.61733043e-01, 1.66065922e-06,\n",
       "        1.19690895e-07, 1.77609350e-03],\n",
       "       [1.75945289e-07, 1.61446769e-05, 2.22775525e-05, 6.35210890e-05,\n",
       "        5.59616780e-08, 2.33134844e-12, 9.99247074e-01, 3.13712633e-07,\n",
       "        8.82054252e-09, 6.50350761e-04],\n",
       "       [6.30941983e-08, 2.28691980e-01, 6.21449172e-01, 6.24919805e-09,\n",
       "        4.11879739e-07, 5.15445892e-04, 1.09298676e-01, 8.78157298e-05,\n",
       "        1.13913458e-12, 3.99563685e-02],\n",
       "       [1.05529036e-02, 5.73100030e-01, 4.06730384e-01, 4.93343407e-03,\n",
       "        1.03338587e-03, 1.01069041e-07, 2.27113115e-03, 1.23215932e-03,\n",
       "        5.86410587e-10, 1.46590508e-04]], dtype=float32)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_0.jpg',\n",
       " 'test_1.jpg',\n",
       " 'test_10.jpg',\n",
       " 'test_100.jpg',\n",
       " 'test_101.jpg',\n",
       " 'test_102.jpg',\n",
       " 'test_103.jpg',\n",
       " 'test_104.jpg',\n",
       " 'test_105.jpg',\n",
       " 'test_106.jpg',\n",
       " 'test_107.jpg',\n",
       " 'test_108.jpg',\n",
       " 'test_109.jpg',\n",
       " 'test_11.jpg',\n",
       " 'test_110.jpg',\n",
       " 'test_111.jpg',\n",
       " 'test_112.jpg',\n",
       " 'test_113.jpg',\n",
       " 'test_114.jpg',\n",
       " 'test_115.jpg',\n",
       " 'test_116.jpg',\n",
       " 'test_117.jpg',\n",
       " 'test_118.jpg',\n",
       " 'test_119.jpg',\n",
       " 'test_12.jpg',\n",
       " 'test_120.jpg',\n",
       " 'test_121.jpg',\n",
       " 'test_122.jpg',\n",
       " 'test_123.jpg',\n",
       " 'test_124.jpg',\n",
       " 'test_125.jpg',\n",
       " 'test_126.jpg',\n",
       " 'test_127.jpg',\n",
       " 'test_128.jpg',\n",
       " 'test_129.jpg',\n",
       " 'test_13.jpg',\n",
       " 'test_130.jpg',\n",
       " 'test_131.jpg',\n",
       " 'test_132.jpg',\n",
       " 'test_133.jpg',\n",
       " 'test_134.jpg',\n",
       " 'test_135.jpg',\n",
       " 'test_136.jpg',\n",
       " 'test_137.jpg',\n",
       " 'test_138.jpg',\n",
       " 'test_139.jpg',\n",
       " 'test_14.jpg',\n",
       " 'test_140.jpg',\n",
       " 'test_141.jpg',\n",
       " 'test_142.jpg',\n",
       " 'test_143.jpg',\n",
       " 'test_144.jpg',\n",
       " 'test_145.jpg',\n",
       " 'test_146.jpg',\n",
       " 'test_147.jpg',\n",
       " 'test_148.jpg',\n",
       " 'test_149.jpg',\n",
       " 'test_15.jpg',\n",
       " 'test_150.jpg',\n",
       " 'test_151.jpg',\n",
       " 'test_152.jpg',\n",
       " 'test_153.jpg',\n",
       " 'test_154.jpg',\n",
       " 'test_155.jpg',\n",
       " 'test_156.jpg',\n",
       " 'test_157.jpg',\n",
       " 'test_158.jpg',\n",
       " 'test_159.jpg',\n",
       " 'test_16.jpg',\n",
       " 'test_160.jpg',\n",
       " 'test_161.jpg',\n",
       " 'test_162.jpg',\n",
       " 'test_163.jpg',\n",
       " 'test_164.jpg',\n",
       " 'test_165.jpg',\n",
       " 'test_166.jpg',\n",
       " 'test_167.jpg',\n",
       " 'test_168.jpg',\n",
       " 'test_169.jpg',\n",
       " 'test_17.jpg',\n",
       " 'test_170.jpg',\n",
       " 'test_171.jpg',\n",
       " 'test_172.jpg',\n",
       " 'test_173.jpg',\n",
       " 'test_174.jpg',\n",
       " 'test_175.jpg',\n",
       " 'test_176.jpg',\n",
       " 'test_177.jpg',\n",
       " 'test_178.jpg',\n",
       " 'test_179.jpg',\n",
       " 'test_18.jpg',\n",
       " 'test_180.jpg',\n",
       " 'test_181.jpg',\n",
       " 'test_182.jpg',\n",
       " 'test_183.jpg',\n",
       " 'test_184.jpg',\n",
       " 'test_185.jpg',\n",
       " 'test_186.jpg',\n",
       " 'test_19.jpg',\n",
       " 'test_2.jpg',\n",
       " 'test_20.jpg',\n",
       " 'test_21.jpg',\n",
       " 'test_22.jpg',\n",
       " 'test_23.jpg',\n",
       " 'test_24.jpg',\n",
       " 'test_25.jpg',\n",
       " 'test_26.jpg',\n",
       " 'test_27.jpg',\n",
       " 'test_28.jpg',\n",
       " 'test_29.jpg',\n",
       " 'test_3.jpg',\n",
       " 'test_30.jpg',\n",
       " 'test_31.jpg',\n",
       " 'test_32.jpg',\n",
       " 'test_33.jpg',\n",
       " 'test_34.jpg',\n",
       " 'test_35.jpg',\n",
       " 'test_36.jpg',\n",
       " 'test_37.jpg',\n",
       " 'test_38.jpg',\n",
       " 'test_39.jpg',\n",
       " 'test_4.jpg',\n",
       " 'test_40.jpg',\n",
       " 'test_41.jpg',\n",
       " 'test_42.jpg',\n",
       " 'test_43.jpg',\n",
       " 'test_44.jpg',\n",
       " 'test_45.jpg',\n",
       " 'test_46.jpg',\n",
       " 'test_47.jpg',\n",
       " 'test_48.jpg',\n",
       " 'test_49.jpg',\n",
       " 'test_5.jpg',\n",
       " 'test_50.jpg',\n",
       " 'test_51.jpg',\n",
       " 'test_52.jpg',\n",
       " 'test_53.jpg',\n",
       " 'test_54.jpg',\n",
       " 'test_55.jpg',\n",
       " 'test_56.jpg',\n",
       " 'test_57.jpg',\n",
       " 'test_58.jpg',\n",
       " 'test_59.jpg',\n",
       " 'test_6.jpg',\n",
       " 'test_60.jpg',\n",
       " 'test_61.jpg',\n",
       " 'test_62.jpg',\n",
       " 'test_63.jpg',\n",
       " 'test_64.jpg',\n",
       " 'test_65.jpg',\n",
       " 'test_66.jpg',\n",
       " 'test_67.jpg',\n",
       " 'test_68.jpg',\n",
       " 'test_69.jpg',\n",
       " 'test_7.jpg',\n",
       " 'test_70.jpg',\n",
       " 'test_71.jpg',\n",
       " 'test_72.jpg',\n",
       " 'test_73.jpg',\n",
       " 'test_74.jpg',\n",
       " 'test_75.jpg',\n",
       " 'test_76.jpg',\n",
       " 'test_77.jpg',\n",
       " 'test_78.jpg',\n",
       " 'test_79.jpg',\n",
       " 'test_8.jpg',\n",
       " 'test_80.jpg',\n",
       " 'test_81.jpg',\n",
       " 'test_82.jpg',\n",
       " 'test_83.jpg',\n",
       " 'test_84.jpg',\n",
       " 'test_85.jpg',\n",
       " 'test_86.jpg',\n",
       " 'test_87.jpg',\n",
       " 'test_88.jpg',\n",
       " 'test_89.jpg',\n",
       " 'test_9.jpg',\n",
       " 'test_90.jpg',\n",
       " 'test_91.jpg',\n",
       " 'test_92.jpg',\n",
       " 'test_93.jpg',\n",
       " 'test_94.jpg',\n",
       " 'test_95.jpg',\n",
       " 'test_96.jpg',\n",
       " 'test_97.jpg',\n",
       " 'test_98.jpg',\n",
       " 'test_99.jpg']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 6, 6, 6, 6, 6, 6, 9])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187,)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(imagenames)\n",
    "b = Y_test\n",
    "a = a.reshape(a.shape[0],-1)\n",
    "a.shape\n",
    "b = b.reshape(b.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((Y_test.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=result, columns=[\"Name\",\"Class\"])\n",
    "df.head()\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_10.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_100.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_101.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Class\n",
       "0    test_0.jpg     0\n",
       "1    test_1.jpg     0\n",
       "2   test_10.jpg     1\n",
       "3  test_100.jpg     6\n",
       "4  test_101.jpg     6"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_32.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_147.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_171.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_114.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_162.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>test_150.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>test_72.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>test_95.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>test_88.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>test_110.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name\n",
       "0     test_32.jpg\n",
       "1    test_147.jpg\n",
       "2    test_171.jpg\n",
       "3    test_114.jpg\n",
       "4    test_162.jpg\n",
       "..            ...\n",
       "182  test_150.jpg\n",
       "183   test_72.jpg\n",
       "184   test_95.jpg\n",
       "185   test_88.jpg\n",
       "186  test_110.jpg\n",
       "\n",
       "[187 rows x 1 columns]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTest = pd.read_csv(\"Test/sample_submission.csv\")\n",
    "YTest.head()\n",
    "YTest.drop(columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yd = pd.merge(df, YTest, how='right', left_on='Name', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Class_x</th>\n",
       "      <th>Class_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_32.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_147.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_171.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_114.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_162.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Class_x  Class_y\n",
       "0   test_32.jpg       1        0\n",
       "1  test_147.jpg       8        0\n",
       "2  test_171.jpg       9        0\n",
       "3  test_114.jpg       6        0\n",
       "4  test_162.jpg       1        0"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yd.to_csv('ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
